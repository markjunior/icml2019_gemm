In recent years, deep learning has been attracting increasing attention from both academia and industry~\cite{lecun2015deep}. With its own advances in algorithmic and architectural design, significant improvement in computational hardware (e.g. GPU and TPU), and availability of enormous amount of labeled data, deep learning has shown success in many domains, such as computer vision, natural language processing, speech recognition, health care, finance, etc. There is no doubt that deep learning solutions will be adopted in even more areas in the upcoming years. 
%It shows promising potential with superior performance and broader penetration in every aspect of IT technology. 
% Inspired by biological nervous systems, deep learning takes advantage of the large computation power nowadays by applying computational models of multiple processing layers to learn representations of data with multiple levels of abstraction \cite{lecun2015deep}. The approach achieves significant performance improvement in the areas of computer vision, natural language processing, audio, biology and game industry, and show promising potentials with higher performance and boarder applications in future. 


% However, with the increasing development in machine learning and deep learning, it becomes difficult for non-machine learning experts to efficiently apply deep learning models to solve real-world problems. In order to make deep learning much easier to be applied and achieve good performance, automated Machine Learning (AutoML) has attracted remarkable attentions, which can autonomously apply suitable machine learning and deep learning models to analyze the potentials of the data and provide beneficially suggestions. Lots of AutoML services and libraries, including AutoWEKA, Auto-sklearn, TPOT, H2O AutoML, Google CLOUD AUTOML, have been developed nowadays and helps both developers and researchers in the areas of artificial intelligence. 

%%%%%%%%%%%%
% https://www.ml4aad.org/automl/
%AutoML systems

However, computing deep learning models (both training and inference) efficiently on various hardware is a difficult task, which involves end-to-end compiler optimization at several levels from computational graphs to operators, and down to executable code on target hardware~\cite{Chen18}. A computational graph is a global view of operators and data flow among them. Within a graph, operators specify various computation that is required for individual operations on tensors. Current optimization techniques at the computational graph level are hardware agnostic and independent from the implementation of operators within a graph. For example, a standard procedure, operator fusion, combines multiple operators into a single kernel, avoiding latency introduced by write-back and loading of intermediate results into memory. At the operator level, existing optimization is mostly limited to specific implementation for a framework (e.g. TensorFlow XLA) or proprietary library for a particular target device (e.g. Nvidia cuDNN). Such libraries have been built mostly based on expert knowledge and manual tuning to perform efficiently and effectively. 

Deep learning models are expected to run on diverse hardware platforms (CPU, GPU, FPGA, ASIC, SoC, etc.) with very different characteristics that can be leveraged to optimize various deep learning operations. To efficiently map deep learning operation/workload to broader range of hardware, TVM has been proposed~\cite{Chen18} as a general compiler framework for automated tensor operator optimization. In this framework, a configuration space can be defined for each operator. Optimization of an operator is to find a configuration that can optimize a performance metric (e.g., the lowest running time). Configuration is the detailed specification of how an operator is computed and executed on target hardware. For example, in matrix multiplication, tiling is required to make computation more efficient, but various tiling strategies may generate configurations that have significantly different performance. Configuration space for individual operators may have different structures and properties. %Current tuning approaches for tensor operators in TVM do not fully exploit useful information that exists among proximal configurations. 

In this paper, we aim at more efficient operator optimization. %further improving the efficiency of configuration tuning. 
We focus on the GEneral Matrix Multiplication (GEMM) operator which is the fundamental operator in deep learning. GEMM computes the product (multiplication) of two matrices and the operator can be translated into nested loops controlled by a fixed set of few parameters. Its optimization can be reduced to finding the optimal combination of parameter values in this set. We analyze structure of its configuration space and design improved tuning approaches for GEMM optimization. The contributions of the paper are three-fold:
\begin{itemize}
\item We consider the relation between different configurations and define the neighboring relation between two configurations. We employ a Markov Decision Process (MDP) for exploration over the configuration space.   
\item Based on the neighboring relations within the configuration space, we propose a Greedy Best-First-Search (G-BFS) guided method and a Neighborhood Actor Advantage Critic (N-A2C) method to search for an optimal configuration given two matrices to be multiplied. %This  for automated compiler-level configuration optimization.
\item We evaluate the performance of our proposed methods in TVM framework for Nvidia Titan XP GPU. We compared them with state-of-the-art GEMM tuners using XGboost~\cite{chen2016xgboost} and RNN controller~\cite{Chen18}. We demonstrate that both our methods can discover high-performance configurations efficiently with smaller fraction of explored configuration space and shorter time to complete. By exploring only 0.1\% of the configuration space, our methods discover configurations of {\bf 24\%} less computing cost than what the XGBoost method can find and configurations of {\bf 40\%} less computing cost than what the RNN method can find, for multiplying two $1024 \times 1024$ matrices. 
\end{itemize}